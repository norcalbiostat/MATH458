---
title: "The Sampling Problem"
author: "Put your name here"
date: today
---

# Introduction

The objective of sample surveys is to make inference about a population from information contained in a sample selected from that population. We are usually interested in estimating some population parameter such as the population mean.

# Populations and Representative Samples (1.2)

A sample is representative if it can be used to "reconstruct" what the population looks like and if we can provide an accurate assessment of how good that reconstruction is.

Some definitions are needed to make the notions of a "population" and a "representative sample" more precise.

### Key Terms

-   **Observational Unit**: 
-   **Target Population**: 
-   **Sample**: 
-   **Sampled population**: 
-   **Sampling unit**: 
-   **Sampling frame**: 

In an *ideal* survey, the sampled population will be identical to the target population. 
:::{.callout-warning icon=false}
### :star: You try it
An online bookseller summarizes readers' reviews of the books it sells. Persons who want to rate a book can submit a review online; the bookseller reports the average rating from all reviews on its website.

Describe the target population, sampling frame, sampling unit, and observation unit. Discuss any possible sources of selection bias or inaccuracy of responses.
:::

----

# Selection Bias (1.3)

**Selection bias** occurs when the target population does not coincide with the sampled population because some population units are sampled at a different rate than intended by the investigator. 

:question: If a survey designed to study household income has fewer poor households than would be obtained in a representative sample, would the survey estimates of the average or median household income be too high? or to low? 

## Some types of selection bias

Summarize briefly and provide a unique example (that is, not the one in the text) for the type of selection bias that you are assigned to review. Be prepared to share this out with the class. 


> After class add all examples provided to your notes. Clean them up (e.g. remove the names and headers)


## Bias everywhere!

Can Bias ever be good? Yes! 


:::{.callout-tip icon=true}
### Example: Early indicators of lung injury associated with vaping (2019)

By Oct '19, over 1,600 cases of lung injuries and 34 deaths were found to be associated with vaping, but the actual cause of injuries were not known. In 2019 a group of researchers (see text for citation) conducted a study that ultimately led to the recommendation that the public stop using these products until more research on the causal association could be conducted. 

This impact survey had the following types of selection bias: 

* Researchers attempted to interview 83 patients who were reported to have lung injuries but only 53 responded (non-response bias). 
* The sampling frame of 83 only came from physician-reported cases, which means there may be bias if the physicians only reported the more serious cases (undercoverage)
* THC is illegal in that state, so patients may have under-reported their use (undercoverage)
* Individuals who vape, incurred a lung injury but didn't seek care were excluded from the study (undercoverage)
:::

Just because your sample may likely contain bias, being up front about it in your reporting (this is what the limitations section is all about) is a very important aspect of open science. 

----

# Measurement Error (1.4)

* **Measurement error**: 
* **Measurement bias**: 

:::{.callout-tip icon=true}
### Example: Ecology surveys

Often in ecological surveys, areas are divided into plots or grids of smaller size. A sample of plots/grids are selected and the number of plants in those selected grids are counted. 

Field researchers have to make a decision about whether or not to count plants directly on the border. If one researcher always counts plants on the boarder as being inside the grid, and another one does not, their estimate will always be higher than the other person. 
:::


## Surveying people 

Obtaining accurate responses is challenging in all types of surveys. Especially when dealing with humans. 

:::{.callout-note appearance=minimal}
### Why humans gotta be so hard?
Write down _all_ reasons you can think of for measurement error in self-report surveys on people. Write down everything that comes to mind, no judgement on if you think its a "good" response or not.  
:::

* 
* 
* 


Clear sampling protocols and thoughtful & validated survey design can minimize measurement error. 

----

# Sampling and Nonsampling errors (1.6)

* Most surveys report a "margin of error", often something like "3 percentage points"
* The **margin of error** 
* **Nonsampling errors** 


:::{.callout-warning icon=false}
### :star: You try it
Go find a poll on a subject that interests you. Share the URL in the #458-class-chat discord channel. 
Report the population of interest, the statistic being estimated, and the margin of error.
Also put this in your notes. 
:::

