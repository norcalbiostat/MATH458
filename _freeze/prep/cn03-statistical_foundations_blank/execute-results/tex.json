{
  "hash": "18028bcc773a0d95b6be094caf29ec64",
  "result": {
    "markdown": "---\ntitle: \"Foundations of Statistical Estimation\"\nauthor: \"Put your name here\"\ndate: today\ndescription: \"We review some of the introductory concepts of statistics that will be a pre-requisite for the remainder of the course.\"\nformat: pdf\nexecute: \n  error: true\n  freeze: true\n---\n\n\n# Introduction\n\nIn this section we review the basic concepts underlying the selection of an estimator of a population parameter, the method for evaluating its goodness, and the concepts involved in interval estimation. Because the bias and the variance of estimators determine their goodness, we need to review the basic ideas concerned with the expectation and variance of a random variable.\n\n## Populations and Samples\n\nStatistical inference centers around using information from a sample to understand what might be true about the entire population of interest. If all we see are the data in the sample, what conclusions can we draw about the population? How sure are we about the accuracy of those conclusions? \n\nOn April 29, 2011, Prince William married Kate Middleton in London. The Pew Research Center reports that 34% of US adults watched some or all of the royal wedding. How do we know that 34% of all US adults watched? Did anyone ask **you** if you watched it? In order to know for sure what proportion of US adults watched the wedding, we would need to ask **all** US adults whether or not they watched. This would be very difficult to do. As we will see, however, we can estimate the _population_ proportion _parameter_ quite accurately with a _sample statistic_, as long as we use a random sample. In the case of the royal wedding, the estimate is based on a poll using a random sample of 1006 US adults.\n\n* _Statistical inference_: \n* _Parameter_: \n* _Statistic_: \n\nGenerally our goal is to know the value of the population parameter exactly but this usually isn't possible since we usually cannot collect information from the entire population. \n\nInstead we can select a sample from the population, calculate the quantity of interest for the sample, and use this sample statistic to estimate the value for the whole population.\n\n\n:::{.callout-warning}\n### You try it\nThe US Census states that 27.5% of US adults who are at least 25 years old have a college bachelor's degree or higher. Suppose that in a random sample  of $n$=200 US residents who are 25 or older, 58 of them have a college bachelor's degree or higher. \n\nWhat is the population parameter? What is the sample statistic? Use correct notation for your answer.\n:::\n\n> write your answer here.\n\nThe value of a statistic for a particular sample gives a _point estimate_ of the population parameter. If we only have the one sample and don't know the value of the population parameter, ....\n\nAfter we have a little more mathematical terminology and foundation, we'll come back to what we mean by \"best estimate\", and examine how we can determine if something is a \"good\" estimate. \n\n----\n\n# Numerical Summaries\n\nThe first thing that we do with data is to summarize it with graphs and numbers. \n\n* Histograms or relative frequency tables can be used to...\n* Once a relative frequency distribution has been established for a population, we can use probability arguments to ...\n* The numerical measures used to summarize the characteristics of a population are defined as ...\n\n:::{.callout-important}\n### Definition: Expected Value\n$$\nE(y) = \n$$\nwhere the summation is over all the values of $y$ for which $p(y)>0$.  \n$p(y)$ is the probability of each value of $y$.\n:::\n\n\n:::{.callout-tip icon=false}\n### Example calculation of $E(y)$ from a discrete probability distribution\n| y   | p(y) |\n|-----|------|\n| 1   | .1   |\n| 2   | .5   |\n| 3   | .4   |\n\n$E(y)=\\sum_{y}yp(y) = (1)(.1) + (2)(.5) + (3)(.4) = 2.3$\n:::\n\n:::{.callout-important}\n### Definition: Population Mean\n$$\n\n$$ \n\nwhere $y$ is a value of a single measurement chosen at random from the population.\n:::\n\n\n:::{.callout-important}\n### Definition: Population Variance & Standard Deviation\n\n$$\\sigma^{2} = V(y)=E(y-\\mu)^{2} = \\sum_{y}\\left(y-\\mu\\right)^{2}*p(y)$$\n\nThe variability of measurements in a population can be measured by the **variance** which is defined as the average squared deviation from the mean between a randomly selected measurement $\\_$ and its mean value $\\_$\n\nThe standard deviation is defined as the square root of the variance, and is denoted $\\_$.\n\nSometimes it's may be convenient to calculate the variance using this formulation: \n\n$$ $$\n:::\n\n\nWe can also calculate these measurements directly from the sample measurements. \n\nIn statistical studies, the population of interest consists of _unknown_ measurements; hence, we can only speculate on the relative frequencies ($p(y)$). In order to gain information about a population we take a sample of $n$, $y_{1},y_{2},...,y_{n}$. We can then infer characteristics about the population. Given our sample data, $y_{1},y_{2},...,y_{n}$, we can calculate the mean and variance:\n\n$$\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n}y_{i}$$\n$$s^{2} = \\frac{1}{n-1}\\sum^{n}_{i=1}\\left(y_{i}-\\bar{y}\\right)^{2}$$\n\n\nWhy do we have $n-1$ in the denominator for $s^2$, but only $n$ in the denominator for $\\bar{y}$?\n\n> put your answer here\n\n\n:::{.callout-warning icon=false}\n### You try it\nWhen a few data points are repeated in a data set, the results are often arrayed in a frequency table. For example, a quiz given to each of 25 students was graded on a four-point scale (0,1,2,3), 3 being a perfect score. \n\nConsider the following results: 16 students scored a 3, 4 students scored a 2, 2 students scored a 1, and 3 scored a 0. Assume this distribution of scores is representative of the population distribution. \n\nCalculate both the sample and population values of the average and standard deviation. \n:::\n\nHere is some starter code. \n\n::: {.cell}\n\n```{.r .cell-code}\ny <- 3:0\nf <- c(16, 4, 2, 3)\np <- c(.64, .16, .08, .12)\ndta <- rep(y, f)\n```\n:::\n\n\n\n## The Finite Population Case (Lohr Ch 2.2)\n\nThe previous section develops results for random sampling from a population considered to be infinite. In such situations, each sampled element has the same chance of being selected and the selections are independent of one another. \n\n* Most sampling problems don't live in an infinite world, but the population is usually finite although it may be quite large. \n* In addition, we may want to take into consideration varying the probabilities with which the units are sampled. \n\n:::{.callout-tip icon=true}\n### Example: Estimate total number of job openings. \nSuppose, for example, we want to estimate the total number of job openings in a city by sampling industrial firms from within that city. Many of these firms will be small and a few firms will be large. In a random sample _of firms_, the size of the firm is not taken into account. However, the number of job openings will be directly dependent on the size of the firm. Thus, we might improve the sample if large firms are more likely to be included in the sample. \n:::\n\n* Suppose the population consists of the set of elements $\\{u_{1},u_{2},...,u_{N}\\}$ and a sample of $n$ elements is to be selected with replacement independently of one another.\n* Let $\\{\\delta_{1},\\delta_{2},...,\\delta_{N}\\}$ represent the respective probabilities of selection for the population elements. \n    - $\\delta_{i}$ is \n    - for the case of random sampling with replacement, each $\\delta_{i} = $\n\n\nAn **unbiased estimator** of the population total, $\\tau$, is given by\n\n$$\n\\hat{\\tau}=\\frac{1}{n}\\sum^{n}_{i=1}\\frac{.}{.}\n$$\n\n> your job is to replace the dots with numbers or symbols, then delete this line. \n\nWhen $\\delta_{i} = 1/N$, we can rewrite this as \n\n$$\n\\hat{\\tau} = \\frac{1}{n}\\sum^{n}_{i=1}\\frac{.}{.} = \\frac{.}{n} \\sum^{n}_{i=1}y_{i} = \n$$\n\nIt is in the best interest to select the $\\delta_{i}$ values in such a way that the _______ is as small as possible. The best practical way to choose the $\\delta_{i}$ is to choose them proportional to a known measurement that is highly correlated with $y_{i}$. \n\n:::{.callout-tip icon=true}\n### Example: Job openings cont. \nOur universe only consists of these $N=4$ firms: A, B, C and D. \n\n| Firm | Jobs ($x$) | Size of firm | $\\delta_{i}$ |\n|------|------------|--------------|--------------|\n| A    | 3          | 70           | 70/580       |\n| B    | 10         | 90           | 90/580       |\n| C    | 25         | 120          | 120/580      |\n| D    | 61         | 300          | 300/580      |\n:::\n\nThe population total of job openings is $\\tau= 99$. But of course we don't know this, so we want to take a sample of $n=2$ firms and count the number of jobs at each firm $x$ as a way to estimate this total. \n\nIf all firms have equal probability of being selected, then the subset of firms $\\{A, B\\}$ have the same chance of being selected as any other subset of two firms such as $\\{A, C\\}$. However, we may want to select firms with probabilities in proportion to their workforce ($\\delta_{i}$).  \n\nWithout adjustment the estimate of the total job openings based on the $\\{A, B\\}$ sample would be: \n$$\n\\hat{\\tau} = N\\bar{X} = \n$$\n\n\nIf we adjust $y_{i}$ based on the probability of selecting firms A and B,\n$$\n\\hat{\\tau} = \\frac{.}{.}\\Big[\\frac{.}{./.} + \\frac{.}{./.}\\Big]  = \n$$\n\n\n**Was this a good estimate of $\\tau$? Why or why not? **\n\n\n# Variability of Estimates\n\n:::{.callout-note appearance=minimal}\n### Turn and talk\nWhy do we usually think of a parameter $\\mu$ or $p$ as a fixed value, while the sample statistic $\\bar{x}$ or $\\hat{p}$ as a random variable?\n:::\n\n> write a sentence or two here based on your discussion\n\nAlong with the point estimate we also want to know how accurate we can expect the point estimate to be. In other words, if we took another random sample of the same size from the population, is the point estimate from this new sample likely to be similar to the first point estimate or are they likely to be far apart.\n\n:::{.callout-tip icon=true}\n### Example: Enrollment in Graduate Programs in Statistics\nGraduate programs in statistics often pay their graduate students, which means that many graduate students in statistics are able to attend graduate school tuition free with an assistantship or fellowship. There are 82 US statistics doctoral programs for which enrollment data were available. The data set `StatisticsPhD` lists all these schools together with the total enrollment of full-time graduate students in each program in 2009.\n\n**What is the average full-time graduate student enrollment in US statistics doctoral programs in 2009? **\n:::   \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstat.phd <- readr::read_csv(here::here(\"___\", \"_______\"))\nhead(stat.phd)\nmean(stat.phd$_______)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: <text>:3:15: unexpected input\n2: head(stat.phd)\n3: mean(stat.phd$_\n                 ^\n```\n:::\n:::\n\n\nBased on the data set, the mean enrollment in 2009 is ____ full-time graduate students. Because this is the mean for the entire population of all US statistics doctoral programs for which data were available that year, we have that $\\mu=$ students.\n\nUse the code below take a random sample of 10 programs from the data file and calculate the mean.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy.sample.programs <- sample(______, size=__)\nmean(______)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: <text>:1:31: unexpected input\n1: my.sample.programs <- sample(__\n                                  ^\n```\n:::\n:::\n\n\n:::{.callout-note appearance=minimal}\n### Turn to your neighbor and discuss the following questions\n\n* Did everyone get the same sample mean?\n* Does your sample mean exactly equal the population mean?\n* If you took another sample of 10, would you get the same sample mean? Why?\n* If we created a histogram of all our sample means, what would it look like? Where would it be centered at? What is the spread of the histogram?\n:::\n\n> write your summary discussion here. \n\nKnowing the behavior of of repeated sample statistics (like the mean in the prior example) is critically important. Let's dig into this a little more by repeating this sampling experiment many times. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmany.means <- replicate(n=_____, {\n  my.sample.programs <- sample(_______, size=10)\n  mean(_______)\n})\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: <text>:1:28: unexpected input\n1: many.means <- replicate(n=__\n                               ^\n```\n:::\n:::\n\n\nLet's visualize the distribution of all those sample means. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(_____)\nsummary(_____)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: <text>:1:7: unexpected input\n1: hist(__\n          ^\n```\n:::\n:::\n\n\nCharacteristics of this distribution:  \n\n* _Shape_: \n* _Center_: \n* _Spread_: \n\n\nWe have just created a _____ of the sample mean. \n\n## Sampling Distribution\n\nA _sampling distribution_ is the distribution of\n\n:::{.callout-note appearance=minimal}\n### Turn to your neighbor and discuss the following questions\n\n* What information might be important to get from a sampling distribution?\n* What would happen if we increased our sample size (_not the number of replicates_) to $n=20$ rather than $n=10$. What about the sampling distribution would change?\n* What would happen if we increased the number of replications (holding $n$ constant) to 1000 instead of 100? What about the sampling distribution would change?\n:::\n\n> write your summary discussion here. \n\nIn elementary statistics you were introduced to the \"Central Limit Theorem\" (CLT). The CLT states that the sampling distribution of $\\bar{y}$ should be \n\n* centered at \n* with a standard deviation of\n* with the shape of the distribution should be approximately \n\n# Properties of Estimators\n\nIn general, suppose that $\\hat{\\theta}$ is an estimator of the parameter $\\theta$. Two properties that we would like $\\hat{\\theta}$ to have are\n\n1. The estimate is **unbiased**: $E(\\hat{.}) = .$.\n2. The estimate is **precise**: $Var(\\hat{.})$ is \n\nTo clarify: \n\n* **_____________ bias** means that the $y$'s are measured inaccurately. \n    - That means an estimator of a total $t$ calculated as $\\hat{t} = \\sum_{i \\in U} y_{i}$ where $U$ is the entire universe, then $\\hat{t}$ itself would not be the true total of interest. \n    - Trying to estimate heights of students, but your ruler is always off 3 cm\n* **_____________ bias** means that the estimator chosen resulted in a bias. \n    - If we calculated the total as $t' = \\sum_{i \\in L} y_{i}$ from a random sample of $L$ units in the universe, $\\hat{t'}$ would be biased. \n    - Trying to estimate heights of students by taking a sample of the shorter students only.\n\nIf two unbiased estimators are available for $\\theta$ we generally prefer the one with the smaller variance.\n\nBecause sometimes we use biased estimators, we often use the _____________ instead of the variance to estimate the **_____________**. \n\n:::{.callout-important}\n### Definition: Bias, Variance, Accuracy\n$$\\mbox{Bias}(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta$$\n\n$$V(\\hat{\\theta})  = E \\Big[(\\hat{\\theta} - E[\\hat{\\theta}])^2\\Big]$$\n\n$$\\mbox{MSE}(\\hat{\\theta}) = V(\\hat{\\theta}) + [Bias(\\hat{\\theta})]^2$$\n:::\n\nRefer to textbook Figure 2.3.\n\n* A is **_____________**. The average position of all arrows is at the center of the target.\n* B is **_____________** but not unbiased. All arrows are close together but systematically away from the center. \n* C is **_____________**. All arrows are close together and near the center of the target. \n\n:::{.callout-tip icon=true}\n### Example\nSuppose probability samples of size $n=2$ are selected from the list `c(1,2,3,4)`, with $\\delta_{i}$ probabilities `c(.4, .4, .1, .1)`. Demonstrate that $\\hat{\\tau}$ is an unbiased estimator of the population total $\\tau$, but its variance is 81.25. \n:::\n\n\nInitial problem setup: Define data/sample/known values as objects in R.  \n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 1:4\ndeltas <- c(.4,.4,.1,.1)\n(tau <- sum(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10\n```\n:::\n:::\n\n\nCreate all possible samples of size $n=2$, and add the probability of selection for that sample. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create all possible samples of size 2\n\n\n# Add the selection probabilities \n```\n:::\n\n\nNote the resulting object is a table/matrix with 16 rows and 4 columns, where each row is a possible sample of $n=2$ from the universe. \n\nNow calculate $\\hat{\\tau} = \\frac{1}{2}\\Big[\\frac{x_1}{\\delta_1} + \\frac{x_2}{\\delta_2}\\Big]$. \n\n\n::: {.cell}\n\n:::\n\n\n_manually verify calculation_\n\n::: {.cell}\n\n:::\n\n\n\nNow calculate $E[\\hat{\\tau}] = \\sum \\hat{\\tau}*p(\\hat{\\tau})$ and $V[\\hat{\\tau}] = E[\\hat{\\tau}] - E[\\hat{\\tau}]^2]$, where $p(\\hat{\\tau}) = \\delta_1*\\delta_2$ is the probability that sample is chosen. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate selection probability \nuniverse$p.hat.tau <- \n(E.tau.hat <- )\n(Var.tau.hat <- )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: <text>:3:15: unexpected ')'\n2: universe$p.hat.tau <- \n3: (E.tau.hat <- )\n                 ^\n```\n:::\n:::\n\n\n:::{.callout-warning icon=false}\n### You try it\nLohr Ch 2 exercises, #1. \n:::\n\n\n# Interval Estimation \n\nIn general, it is usually not enough to just give a point estimate when estimating a population parameter. Why?\n\n> \n\n## Bounds on Estimators\n\nThe objective of sampling is to estimate the population parameters, such as the mean or the total of a population from information contained in the sample. The experimenter controls the quantity of information by choosing an appropriate sample size. How can we determine how many sampling units to select? \n\n> \n\nSuppose that we are trying to estimate some parameter $\\theta$ using the sample estimator $\\hat{\\theta}$. We want the value of _________ to be small. We refer to the value of _________ as the **error** because it is the difference between the _________ value and the _________ value. \n\n\n:::{.callout-note appearance=minimal}\n### Turn & talk\nWhat is the difference between the _error_ and _bias_?\n:::\n\n> \n\n\nWe might want to specify that the absolute value of the error is less than some number, say $B$. Thus,\n$$\n\\mbox{Error of Estimation}=|\\theta-\\hat{\\theta}|<B\n$$\n\nWe should also define a probability ($1-\\alpha$) such that our error is less than $B$ if we were to take repeated samples. \n$$\nP\\left(|\\theta-\\hat{\\theta}|<B\\right)=1-\\alpha\n$$\n\nWe will often select $B$ to be approximately ___________ of $\\hat{\\theta}$. As we saw earlier, many of the statistics that we will discuss exhibit a normal sampling distribution even when the population distribution is skewed.\n\n\n## Standard Error\n\n:::{.callout-important}\n### Definition: Standard Error\nThe _standard error_ of a statistic is ...  \n\n:::\n\n\nThe standard error of a statistic tells us how much the sample statistic will vary from sample to sample. In situations like above where we can examine the distribution of the sample statistic using simulation, we can estimate the standard error by taking the sample standard deviation of the sampling distribution. In other situations we can use closed form mathematical formulas to calculate the standard error.\n\n:::{.callout-tip icon=true}\n### Example Grad program example cont. \nEstimate the standard error for the mean enrollment in statistics PhD programs for a sample size of 10 and also a sample size of 20. \n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd(many.means) \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(x): object 'many.means' not found\n```\n:::\n:::\n\n\n\n## Confidence Intervals\n\nWhen the distributions are relatively symmetric and bell-shaped, the 95% rule tells us that approximately 95% of the data values fall within two standard deviations of the mean. Applying the 95% rule to sampling distributions, we see that about 95% of the sample statistics will fall within two standard errors of the mean. We use this rule many times to form what we call an approximate 95% confidence interval which gives us a range for which which we are quite confident that captures the true parameter we are trying to estimate.\n\nWhen using a formula to calculate an approximate 95% confidence interval, use ......\n\n\n:::{.callout-tip icon=true}\n### CI for PhD program enrollment\nBased on our example, what would be a 95% confidence interval for $\\mu$ the true mean total enrollment for PhD programs in statistics.\nInterpret this confidence interval in context of the problem.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(LCL <- )\n(UCL <- )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: <text>:1:9: unexpected ')'\n1: (LCL <- )\n            ^\n```\n:::\n:::\n\n\n> We can be 95% confident that the true mean total enrollment for PhD programs in statistics is covered by the interval ( ). \n\n\n:::{.callout-note appearance=minimal}\n### Turn & talk\n\nConsider the following interpretation of the above confidence interval. \n\n> We can be 95% confident that PhD programs in Statistics have a total enrollment of between ______ and _____ students. \n\nWhy is this an incorrect interpretation? \n\n:::\n\n> Write your answer here\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}