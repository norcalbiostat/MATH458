{
  "hash": "499c1b10c596820eb64ea99efa83a920",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Simple Random Sampling\"\ndescription: \"SRS is the basic form of probability sampling, and serves as the basis for more complicated forms.\"\ndate: 2/24/25\nformat: \n  html: \n    toc: true\n    toc_float: true\nexecute:\n  warning: false\n  message: false\n---\n\n\n\n::: {.callout-note appearance=\"minimal\"}\nThese notes use functions from the `sampling`, `survey` and `knitr` packages. See the [formulas](https://sampling-458.netlify.app/notes/formulas.html) page for links to vignettes and handbooks. [The best way to learn a new package is to reference the help file and vignette often for examples.  The R Companion for the book (free pdf from book website) is also very helpful. ]{.aside}\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n# Introduction\n\nThis section will aim to answer the following questions: \n\n* How can we draw a simple random sample of observations from a data set both with, and without replacement: \n* What is the finite population correction (fpc) and why do we need it? \n* What are sampling weights, why do we need them, and how are they created? \n* How do we calculate parameter estimates from an SRS that account for both the fpc and sampling weights? \n\n# Drawing a Simple Random Sample (Lohr Ch 2.3)\n\nRecall there are two ways to draw simple random samples, with and without replacement.\n\n::: callout-important\n### Definition: Simple random sample (SRSWR) with replacement:\n\nA SRSWR of size $n$ from a population of size $N$ can be thought of as drawing $n$ independent samples of size 1. Each unit has the same probability of selection: $\\delta_{i} = \\frac{1}{N}$\n\nThe procedure is repeated until the sample has $n$ units, which may include duplicates.\n:::\n\n::: callout-important\n### Definition: Simple random sample (SRS) without replacement:\n\nA SRS of size $n$ is selected so that every possible subset of $n$ distinct units in the population has the same probability of being selected as the sample. There are $\\binom{N}{n}$ possible samples, resulting in a selection probability for an individual unit $\\delta_{i} = \\frac{n}{N}$. (See Lohr 2.10 and Appendix A for derivation)\n:::\n\n## Intentionality in sampling\n\nRandom does not mean haphazard, contrary it's actually quite intentional. Avoid selecting a sample that you \"feel\" is random or representative of the population. These practices can lead to bias and lack of generalizability.\n\nTo avoid the haphazard nature of \"blindly choosing\", or worse looking at what was sampled and changing it because \"it doesn't look random enough\", we use techniques that leverage pseudo-random number generating algorithms.\n\n\n## Drawing a SRS using a computer\n\n::: callout-important\n### Process \n\n1.  Generate a list of all observational units in the population (sampling frame).\n2.  Assign each observational unit a unique number, from 1 to the size of the sampling frame $N$.\n3.  Use a computer to draw $n$ numbers from 1 to $N$ without replacement.\n4.  Subset the data to keep only the selected rows.\n:::\n\n:::{.callout-tip icon=true}\n### Example: Sampling Statistics PhD programs. \nTo _demonstrate_ this example, lets only grab the first 10 programs in the StatisticsPhD data set. From that we'll draw a sample of $n=4$ programs out of these 10. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstats <- readr::read_csv(here::here(\"data\", \"StatisticsPhD.csv\"))\n(stats10 <- stats[1:10,])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 3\n   University                      Department    FTGradEnrollment\n   <chr>                           <chr>                    <dbl>\n 1 Baylor University               Statistics                  26\n 2 Boston University               Biostatistics               39\n 3 Brown University                Biostatistics               21\n 4 Carnegie Mellon University      Statistics                  39\n 5 Case Western Reserve University Statistics                  11\n 6 Colorado State University       Statistics                  14\n 7 Columbia University             Biostatistics               64\n 8 Columbia University             Statistics                 196\n 9 Cornell University              Statistics                  78\n10 Duke University                 Statistics                  31\n```\n\n\n:::\n:::\n\n\n:::\n\n### Using the `sample()` function\n\n**without replacement**\n\n\n::: {.cell}\n\n```{.r .cell-code}\npop.idx <- 1:NROW(stats10)  # Steps 1, 2\n(idx <- sample(pop.idx, 4)) # Step 3 \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3 4 6 8\n```\n\n\n:::\n\n```{.r .cell-code}\nstats10[idx,]               # Step 4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  University                 Department    FTGradEnrollment\n  <chr>                      <chr>                    <dbl>\n1 Brown University           Biostatistics               21\n2 Carnegie Mellon University Statistics                  39\n3 Colorado State University  Statistics                  14\n4 Columbia University        Statistics                 196\n```\n\n\n:::\n:::\n\n\n\n* Rows 3, 4, 6, 8 were chosen. \n\n**with replacement**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(4134) # again, for demonstration of duplicate records\n(idx.with.dups <- sample(pop.idx, 4, replace=TRUE)) #3 \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  8 10  4  4\n```\n\n\n:::\n\n```{.r .cell-code}\nstats10[idx.with.dups,] #4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  University                 Department FTGradEnrollment\n  <chr>                      <chr>                 <dbl>\n1 Columbia University        Statistics              196\n2 Duke University            Statistics               31\n3 Carnegie Mellon University Statistics               39\n4 Carnegie Mellon University Statistics               39\n```\n\n\n:::\n:::\n\n\n\n* Rows 8, 10, 4, 4 were chosen. \n* Carnegie (row 4) was sampled twice. \n\n## Using the `sampling` package\n\n* The functions `srswr(n,N)` and `srswor(n,N)` draw SRS with, and without replacement respectively. \n* Each take two arguments: $n$ the sample size, and $N$ the population size. \n    - The vector returned is a vector of length $N$ that indicates how many times that position in the vector is selected.  \n    Then the `getdata()` function is used to extract the values from the population the indicated number of times.\n\n**without replacement**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(choose.these.wor <- srswor(4, 10)) # Steps 1,2,3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 0 0 1 0 0 0 0 1 1\n```\n\n\n:::\n\n```{.r .cell-code}\ngetdata(stats10, choose.these.wor)  # Steps 4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  ID_unit                 University Department FTGradEnrollment\n1       1          Baylor University Statistics               26\n2       4 Carnegie Mellon University Statistics               39\n3       9         Cornell University Statistics               78\n4      10            Duke University Statistics               31\n```\n\n\n:::\n:::\n\n\n\n\n**with replacement**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(4134)\n(choose.these.wr <- srswr(4,10)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0 1 0 1 0 0 0 2 0 0\n```\n\n\n:::\n\n```{.r .cell-code}\ngetdata(stats10, choose.these.wr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  University                 Department    FTGradEnrollment\n  <chr>                      <chr>                    <dbl>\n1 Boston University          Biostatistics               39\n2 Carnegie Mellon University Statistics                  39\n3 Columbia University        Statistics                 196\n4 Columbia University        Statistics                 196\n```\n\n\n:::\n:::\n\n\n\n* Again, notice Columbia was chosen twice when sampling with replacement. \n* Interestingly, the result from sampling without replacement added a column called `ID_unit` on it that denotes the row it was sampled from. \n\n:::{.callout-warning icon=false}\n### You try it \n\nThe U.S. government conducts a Census of Agriculture every five years, collecting data on all farms (defined as any place from which \\$1000 or more of agricultural products were produced and sold). The file `agpop.csv` (textbook data) contains historical information from 1982, 1987, and 1992 on the number of farms, total acreage devoted to farms, number of farms with fewer than 9 acres, and number of farms with more than 1000 acres for the population consisting of the $N=3078$ counties and county-equivalents in the United States.\n\nDraw a sample of 300 farms without replacement using both `sample` and `srswor`. Save one of these data frames with the name `ag.srs` for later use. \n:::\n\n:::{.callout-warning icon=false collapse=\"true\" appearance=minimal}\n### Solution\nImport the data and define our sample and population sizes. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nag <- readr::read_csv(here::here(\"data\", \"agpop.csv\")) \nN <- NROW(ag)\nn <- 300\n```\n:::\n\n\n\n**Using the `sample()` function**\n\n[Get in the habit of opening the data set and visually looking at your process at each step. The best way to learn is to check that you know exactly what was done at each step.]{.aside} Generate list of numbers for each observational unit, then draw 5 numbers without replacement.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsampling.frame <- 1:N #1, 2\nsample.idx <- sample(sampling.frame, n, replace=FALSE) #3\nhead(sample.idx)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1788   38  450 1019 2976 1031\n```\n\n\n:::\n:::\n\n\n\nCreate a subset data frame with only the rows that were chosen and stored in the vector `get.these`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample.ag <- ag[sample.idx, ]  #4\nhead(sample.ag[,1:5]) # only showing first 5 columns as an example\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  county         state acres92 acres87 acres82\n  <chr>          <chr>   <dbl>   <dbl>   <dbl>\n1 BUFFALO COUNTY NE     587595  581861  567657\n2 HALE COUNTY    AL     167583  154581  179618\n3 LIBERTY COUNTY GA      15583   18248   19965\n4 HICKMAN COUNTY KY      99066   95560  105051\n5 PIERCE COUNTY  WI     272876  269644  298538\n6 LEE COUNTY     KY      20803   23097   22866\n```\n\n\n:::\n:::\n\n\n\n**Using the `srswor()` function**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1067)\nsrswor.idx <- srswor(n, N)\nag.srs <- getdata(ag, srswor.idx) \n```\n:::\n\n\n:::\n\n\n# Formulas for Estimation\n\nBelow is a table of common statistics and how they are estimated under the SRS framework. This table can also be found on the [formulas](https://sampling-458.netlify.app/notes/formulas.html) page. \n\n| Measure    | Unbiased Estimate $(\\hat{\\theta})$         | Estimated variance of $(\\hat{\\theta})$                             |\n|------------------|-------------------------|-----------------------------|\n| Mean       | $\\bar{y} = \\frac{1}{n}\\sum_{i\\in S} y_{i}$ | $\\hat{V}(\\bar{y}) = (1-\\frac{n}{N})\\frac{s^{2}}{n}$                |\n| Total      | $\\hat{\\tau} = N\\bar{y}$                    | $\\hat{V}(\\hat{\\tau}) = N^{2}\\hat{V}(\\bar{y})$                      |\n| Proportion | $\\hat{p} = \\bar{y}$                        | $\\hat{V}(\\hat{p}) = (1-\\frac{n}{N})\\frac{\\hat{p}(1-\\hat{p})}{n-1}$ |\n\n* $i \\in S$ : Unit $i$ is an element in the sample $S$\n\nDid you notice something different about the formula for the variances? \n\n::: callout-important\n### Finite Population Correction\n\n$$\\Big(1-\\frac{n}{N}\\Big)$$\n\nThe larger % of the population that you include in your sample (sampling fraction = $\\frac{n}{N}$), the closer you are to a census, the smaller the variability your estimate will have.\n:::\n\n* Most samples that are taken from a very large population, the fpc is close to 1.\n* So the variance is more determined by the size of the sample, not the % of the population sampled.\n\n:::{.callout-tip icon=true}\n### Example\nCalculate the estimated standard deviation of the sample mean $\\sqrt{\\hat{V}(\\bar{y})}$ of the the number of acres devoted to farms in 1992 (variable `acres92`). Interpret this number. \n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny.bar <- mean(ag.srs$acres92)\ns2 <- sum((ag.srs$acres92-y.bar)^2)/(n-1)\n(sd.ybar <- sqrt((1-n/N)*(s2/n)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 24924.16\n```\n\n\n:::\n:::\n\n\n\n[Inline R code: `prettyNum(sd.ybar, big.mark=',')`]{.aside}\nSample means generated from samples of size 300 will vary from sample to sample by 24,924.16 acres. \n\n\n:::{.callout-warning icon=false}\n### You try it\nUsing a random sample of 500 farms, estimate the standard deviation of the sample proportion of the number of farms with less than 200,000 acres. \n\nHint(s)\n\n* Use the `srswor` function to draw the sample\n* create an binary indicator to identify farms meeting the criteria\n* use the `mean` function to calculate the sample proportion\n* use the formula to calculate the sd of the proportion\n:::\n\n:::{.callout-warning icon=false collapse=\"true\" appearance=minimal}\n### Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn2 <- 500\nsrswor.idx2 <- srswor(n2, NROW(ag))\nsample.ag.500 <- getdata(ag, srswor.idx2)\n\np.hat <- mean(sample.ag.500$acres92<200000)\n(s.phat <- sqrt((1-n2/N)*(p.hat * (1-p.hat))/(n2-1)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02046818\n```\n\n\n:::\n:::\n\n\n\nThe estimated proportion of number of farms with less than 200k acres varies by 2.04% from sample to sample. \n\n:::\n\n:::{.callout-important icon=false collapse=\"true\" appearance=minimal}\n### Clean up\nAs we go through these notes, we create a lot of the same named objects, like `n` and `N`, or `idx` and `idx2`. Every once in a while its a good idea to clean out your global environment to not get confused. Use the `rm()` function to remove everything except the population `ag`, our sample of 300 `ag.srs`, and their respective sample sizes: `n` and `N`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nls()[!ls() %in% c(\"ag\", \"ag.srs\", \"n\", \"N\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"choose.these.wor\" \"choose.these.wr\"  \"idx\"              \"idx.with.dups\"   \n [5] \"n2\"               \"p.hat\"            \"pop.idx\"          \"s.phat\"          \n [9] \"s2\"               \"sample.ag\"        \"sample.ag.500\"    \"sample.idx\"      \n[13] \"sampling.frame\"   \"sd.ybar\"          \"srswor.idx\"       \"srswor.idx2\"     \n[17] \"stats\"            \"stats10\"          \"y.bar\"           \n```\n\n\n:::\n:::\n\n\n\n:::\n\n# Sampling Weights (Lohr Ch 2.4)\n\nRecall that a goal of sampling is to obtain a representative sample, one that is similar to the true unknown population. Thus, conceptually if we duplicate certain units from our sample a certain amount of times, we could \"reconstruct\" what the population looks like. That is, we could create $w_{i}$ copies of unit $i$ for each unit in the sample. \n\n::: callout-important\n### Definition: Sampling Weight (Design weight)\n\nInverse of the inclusion/selection probability for unit $i$. \n\n$$w_{i} = \\frac{1}{\\delta_i}$$\n\nAlso interpreted as the number of population units represented by unit $i$.\n:::\n\nIn an SRS, each unit has an inclusion probability of $\\delta_{i} = \\frac{n}{N}$, so the sampling weights are all $w_{i} =\\frac{N}{n}$. \n\nWe don't _actually_ make $w_{i}$ copies of record $i$, but use these weights as a multiplier in our estimation calculations. \n\n|         Population size         |                   Total                    |                   Mean                    |\n|:---------------------:|:-----------------:|:-----------------------:|\n| $\\hat{N} = \\sum_{i \\in S}w_{i}$ | $\\hat{\\tau} = \\sum_{i \\in S}w_{i}y_{i}$ | $\\bar{y} = \\frac{\\hat{\\tau}}{\\hat{N}}$ |\n\nThese weighted estimators are used in all probability sampling designs. \n\n:::{.callout-tip icon=true}\n### Example: Calculating weighted estimates\nEstimate the total and average number of acres devoted to farms in 1992 using both weighted and unweighted estimates. Then compare these values to the parameter. \n:::\n\nThe sampling weights are $w_{i} = \\frac{3078}{300}$ for each unit $i$ in the sample, so we'll add that on as a new column before calculating the weighted estimates. \n[See Lohr Table 2.1 for a nicer visual of the data frame with weights. ]{.aside}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nag.srs$wt <- N/n\n(N.hat <- sum(ag.srs$wt)) # just to confirm to myself\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3078\n```\n\n\n:::\n:::\n\n\n\nCalculate weighted and unweighted estimates, then the pop parameters. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntau.hat.wt <- sum(ag.srs$acres92*ag.srs$wt)\ny.bar.wt   <- tau.hat.wt/N.hat\ntau.hat.nowt <- sum(ag.srs$acres92)\ny.bar.nowt   <- mean(ag.srs$acres92)\nmu  <- mean(ag$acres92)\ntau <- sum(ag$acres92)\n```\n:::\n\n\n\nPackage it in a data frame for easier viewing. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(\n  Measure = c(\"Total\", \"Mean\"), \n  Parameter = c(tau,mu),\n  Unweighted = c(tau.hat.nowt, y.bar.nowt), \n  Weighted = c(tau.hat.wt, y.bar.wt)\n  ) |> knitr::kable(align = 'lccc', \n             caption = \"Comparing weighted and unweighted estimates\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Comparing weighted and unweighted estimates\n\n|Measure | Parameter | Unweighted |  Weighted   |\n|:-------|:---------:|:----------:|:-----------:|\n|Total   | 943951718 | 90345498.0 | 926944809.5 |\n|Mean    |  306677   |  301151.7  |  301151.7   |\n\n\n:::\n:::\n\n\n\nNote that when we have an SRS with equal sampling weights $w_{i} = \\frac{N}{n}$, the weighted mean is equal to the unweighted mean. \n\n:::{.callout-warning icon=false}\n###  You try it\nCalculate the proportion of farms with less than 200k acres, with, and without weights. Compare to the population proportion. \n:::\n\n:::{.callout-warning icon=false collapse=\"true\" appearance=minimal}\n### Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nag.srs$lt200k <- 1*(ag.srs$acres92<200000)\n(p.hat.nowt <- mean(ag.srs$lt200k))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5533333\n```\n\n\n:::\n\n```{.r .cell-code}\n(p.hat.wt   <- sum(ag.srs$lt200k * ag.srs$wt)/N)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5533333\n```\n\n\n:::\n\n```{.r .cell-code}\n(p          <- mean(ag$acres92<200000))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5175439\n```\n\n\n:::\n:::\n\n\n:::\n\n# Analysis using the `survey` package (Lohr Ch 2.6)\n\nSurvey designs are specified using the `svydesign` function. The main arguments to the the function are id to specify sampling units, weights to specify sampling weights, and fpc to specify finite population size corrections. These arguments should be given as formulas, referring to columns in a data frame given as the data argument.\n[Similar to using `group_by` in dplyr, that adds a \"flag\" to the data set indicting that all subsequent actions are to be done to each group separately, the `svydesign` function adds information to the data set so subsequent actions know how to incorporate measures like weights and strata]{.aside}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survey)\nag.srs.dsgn <- svydesign(id = ~1, weights = ~wt, fpc = rep(N,n), data = ag.srs)\n```\n:::\n\n\n\nThe `id` argument specifies the clusters. We are not using any clustering, so each unit has it's own id. \n\n## Point and interval estimates\n\nSurvey design adjusted estimates can be obtained using `svymean` and `svytotal`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsvymean(~acres92, ag.srs.dsgn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          mean    SE\nacres92 301152 24924\n```\n\n\n:::\n\n```{.r .cell-code}\nsvytotal(~acres92, ag.srs.dsgn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            total       SE\nacres92 926944810 76716552\n```\n\n\n:::\n\n```{.r .cell-code}\nsvymean(~lt200k, ag.srs.dsgn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          mean     SE\nlt200k 0.55333 0.0273\n```\n\n\n:::\n:::\n\n\n\nEstimates for multiple variables can be obtained at the same time. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsvymean(~acres92+farms92, ag.srs.dsgn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             mean        SE\nacres92 301151.66 24924.156\nfarms92    582.28    24.156\n```\n\n\n:::\n:::\n\n\n\nYou can pass the results to construct confidence intervals. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsvytotal(~acres92+farms92, ag.srs.dsgn) |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            2.5 %     97.5 %\nacres92 776583131 1077306488\nfarms92   1646531    1937985\n```\n\n\n:::\n:::\n\n\n\nWe can be 95% confident that the interval (1,646,531, 1,937,985) covers the true number of farms in the united states in 1992. \n\n:::{.callout-warning icon=false}\n###  You try it\nUsing your sample of 300 farms, estimate the total number of farms in the United States in 1987 and the average farm size in acres for the same year. Report both point and interval estimates. \n:::\n\n\n\n",
    "supporting": [
      "cn03-SRS_complete_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}