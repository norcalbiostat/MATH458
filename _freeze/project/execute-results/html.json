{
  "hash": "6c6236e113a9f13ad7d6eb240af3985c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Project\"\nformat: \n  html: default\n---\n\n\n# Project Overview: Shaping the Future of Math & Data Science\n\nThis semester, you will go on a real-world project that will directly impact the future of the Mathematics and Data Science programs at Chico State. Working collaboratively as a class, you will design, implement, and analyze an alumni survey to gather valuable insights about their experiences and career paths. This is your chance to apply the sampling and statistical analysis methods you've learned in a practical and meaningful way.\n\nThis project isn't just about crunching numbers; it's about teamwork, communication, and project management. As a class you will be responsible for:\n\n-   Defining Roles & Responsibilities: Assign yourselves specific roles within the project (e.g., survey design team, data analysis team, communication lead).\n-   Task Management & Timelines: Establish clear timelines and track progress to ensure successful completion of each project phase.\n-   Stakeholder Communication: Get stakeholder (Math Department faculty, Career center) input in the questions being asked.\n-   Design & Implementing Multiple Sampling Frameworks: Implement multiple sampling methods (e.g., simple random, stratified, cluster) to select representative samples of alumni.\n-   Data Collection & Analysis: Collect survey responses, clean the data, and perform appropriate statistical analyses to answer key research questions. You will also need to compare estimates obtained across the different sampling frameworks to assess their impact on the results.\n-   Final Presentation: Present your findings and recommendations and insights to the Math Department or the assessment committee.\n\nThis is a full class collaborative effort, requiring everyone's active participation and contribution. Every student should take lead on at least one aspect or activity. Your collective efforts will provide valuable data to inform curriculum development, program improvements, and future initiatives within the Mathematics & Statistics departments. Embrace this opportunity to make a real difference!\n\n# Milestones\n\n1.  **Define Project Goals and Stakeholder Input:** Documented agreement on the survey's objectives and how the results will be used, based on input from stakeholders.\n2.  **Literature Review and Best Practices Research:** Review of existing alumni surveys and research on best practices in survey design and implementation.\n3.  **Create Sampling Frame:** A list of the target population from which the sample will be drawn.\n4.  **Develop & Test Questionnaire:** Draft questionnaire, pilot testing, and revisions based on feedback.\n5.  **Design Sampling Strategy:** Detailed plan for selecting the sample, including justification for the chosen method and sample size calculations.\n6.  **Collect Data:** Completed survey responses. Include metrics on response rate and efforts to address non-response bias.\n7.  **Data Cleaning:** Prepare the data for analysis. Screen for outliers, missing or invalid responses. Create necessary metrics. Create basic tables and summaries for each measures.\n8.  **Data Analysis:** Create analysis plan, conduct analysis and compile results, create visualizations.\n9.  **Final Presentation:** Presentation to stakeholders\n10. **Final Report:** Comprehensive written report documenting all aspects of the project.\n\n# Parameters to be Estimated\n\n* Average salary expectations for 1, 2, and 5 years.\n* Average time taken by alumni to secure their first job\n* Proportion of alumni who found their degree valuable\n* Proportion of alumni working in different career sectors\n* Proportion of alumni who were accepted to or attended graduate school (mathematics oriented) or with a terminal degree\n* Proportion of alumni who felt they were prepared\n\n\n# Sample Size Determinations\n\nSince most of the parameters to estimate are proportions we will determine the sample size under that framework. Our sampling frame (population size) is $N=300$. \n\n* We have no prior knowledge of the estimated proportions, so $\\hat{p} = \\hat{q} = .5$. We will use this for our estimate of $S$. \n* We will set our confidence to be 95%, thus $\\alpha = .05$\n* We will allow our margin of error to vary between 1% and 25%\n\nI created a graph to plot the sample size under an SRS framework using equation 2.30, 2.31 as a function of the margin of error `e`. We can use this to make a determination of a general total sample size that we will aim for in each of the sampling designs. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsrs.n <- function(e){\n  n0 <- 1.96^2 / (4*e^2)\n  n <- n0 / (1+n0/300)\n  return(n)\n}\ne <- seq(.01, .25, by = .01)\nplot(e, srs.n(e), type = \"l\")\n```\n\n::: {.cell-output-display}\n![](project_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsrs.n(seq(.05, .25, by = .05))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 168.45182  72.75023  37.36771  22.23080  14.61766\n```\n\n\n:::\n:::\n\n\n\n# Sampling Design\n\nMultiple sampling designs were developed as described below. \n\nRead in Sampling frame\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sampling)\nlibrary(tidyverse)\n\nsampling.frame <- googlesheets4::read_sheet(frame.url) |> \n  janitor::clean_names() %>%\n  select(fixed_id:assigned_contact_person)\n```\n:::\n\n\nThe population size is determined by the size of our sampling frame, and the sample size was determined using the graph above and a class discussion. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- NROW(sampling.frame)\nn <- 150\n```\n:::\n\n\n## SRS\n\nWe draw a simple random sample from the entire alumni population without stratifying by any specific variable. Each alumni has an equal probability of being selected, regardless of graduation year, major, or number of majors. This method is easy to implement and ensures that the sample is unbiased with respect to all known and unknown variables. While this approach may not capture differences in key subgroups (e.g., income variation by major or graduation year), it provides a fair and representative overview of the overall alumni population. Since the cost of observation is the same for each unit (zero), SRS is a reasonable choice, particularly when subgroup-specific insights are not the primary goal of the study.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass.seed <- 7+3+5+27+4+510+24+37+42+6+11+64\nset.seed(class.seed)\nsrs.idx <- sampling::srswor(n, N)\n\nsrs.sample <- getdata(sampling.frame, srs.idx) %>% \n  select(fixed_id) %>%\n  mutate(srs_prob = n/N)\n```\n:::\n\n\n\n## Stratified on Year\n\nIn our study we chose to stratify the data to make sure that an alumnus graduation year was accurately represented in the sample. Satisfying typically improves the accuracy and representation of a sample and thus we can accurately account for differences in years. We chose to stratify by year specifically because alumni experiences, job placements, and pay may all depend on how long it has been since they graduated. This is especially important in the past 5-10 years because it would not be surprising if alumni who graduated in or around covid had a much different experience overall than those prior. \n\nWe chose to use proportional allocation for our results to more accurately represent the population as a whole. We made the stratum sample sizes proportional to the stratum population sizes. The formula for sample size being $n_{h}=\\frac{N_{h}}{N}n$ where $N_{h}$ is the population size of the stratum we are concerned with.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(class.seed)\nstrata2.frame <- sampling.frame %>% arrange(expected_grad_year) # sort first\n\np.1 <- sum(strata2.frame$expected_grad_year==2015)*.5\np.2 <- sum(strata2.frame$expected_grad_year==2016)*.5\np.3 <- sum(strata2.frame$expected_grad_year==2017)*.5\np.4 <- sum(strata2.frame$expected_grad_year==2018)*.5\np.5 <- sum(strata2.frame$expected_grad_year==2019)*.5\np.6 <- sum(strata2.frame$expected_grad_year==2020)*.5\np.7 <- sum(strata2.frame$expected_grad_year==2021)*.5\np.8 <- sum(strata2.frame$expected_grad_year==2022)*.5\np.9 <- sum(strata2.frame$expected_grad_year==2023)*.5\np.10 <-sum(strata2.frame$expected_grad_year==2024)*.5\n\nalloc <- ceiling(c(p.1, p.2,p.3,p.4,p.5,p.6,p.7,p.8,p.9,p.10))\n\nstrata.idx <- sampling::strata(data = strata2.frame,      # data set\n                 stratanames = \"expected_grad_year\", \n                 size = alloc,      # stratum sample sizes \n                 method = \"srswor\")     # method for selecting within strata\n```\n:::\n\n\nNow we extract the unique person identifier (`fixed_id`) and the sampling probability from the selected sample. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nstrata.year.sample <- getdata(sampling.frame, strata.idx) %>% \n  select(fixed_id, strata_year_prob = Prob)\n```\n:::\n\n\n## Stratified on Major\n\nWe hypothesize that students who studied different focuses will be pursuing different types of careers and making different kinds of salaries. Students who double or triple majored will also not have the same experiences as those who share one of their majors. We expect that by stratifying by major, with those with more than one major in a separate stratum, we should be able to expect widely different stratum means for variables like annual income. Since different majors have different course requirements, their feedback on the university will also be different by major. Since we are interested in multiple variables and the observation cost in each stratum will be the same, in this case zero, proportional allocation makes sense as a choice.\n\nFirst we create a new variable with either a student’s major or if they had multiple majors stored. **Will Stratify by this variable**\n\n:::{.callout-important}\n#### Oops\nWe have clusters of psych majors b/c their math major was secondary... \n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsampling.frame$stratamajor <- sampling.frame$major_1\nsampling.frame$stratamajor[!is.na(sampling.frame$major_2)] = \"Multiple Majors\"\n\nsampling.frame.sort.major <- sampling.frame %>% arrange(stratamajor)\n```\n:::\n\n\nLet `p` be the proportion of total population sampled. We will calculate size of samples drawn from each strata as .... _need equations/info here_\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- n/N\n\nstrata.size <- table(sampling.frame.sort.major$stratamajor) |> data.frame()\nstrata.size$n_h <- round(strata.size$Freq * p)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(class.seed)\nstrata.major.idx <- sampling::strata(data = sampling.frame.sort.major, \n                              stratanames = \"stratamajor\", \n                              size = strata.size$n_h, \n                              method = \"srswor\")\n\nstrata.major.sample <- getdata(sampling.frame.sort.major, strata.major.idx) %>% \n  select(fixed_id, strata_major_prob = Prob)\n```\n:::\n\n\n\n## Cluster: Same year same major\n\n> need description\n\n### One Stage Cluster:\n\nBasic organizing\n\n::: {.cell}\n\n```{.r .cell-code}\n# renaming to cluster for simplicity\nsampling.frame$cluster <- sampling.frame$expected_grad_year\n\n# getting unique cluster ids based on year\n(all_clusters <- unique(sampling.frame$cluster))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024\n```\n\n\n:::\n\n```{.r .cell-code}\n# viewing frequencies of years\n(table <- table(sampling.frame$cluster) )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 \n  29   20   27   32   40   25   29   36   35   25 \n```\n\n\n:::\n\n```{.r .cell-code}\n# picking my sample size, will round to the nearest whole number\nweighted.mean(table)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 29.8\n```\n\n\n:::\n:::\n\n\nNOTE: the number of sampled clusters is based on the average of 30 grads per year to get roughly 150 individuals in the final total sample.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM <- length(unique(sampling.frame$cluster)) # total number of clusters (PSUs, aka GROUPS) in population\nm  <- 5 # the number of sampled clusters\n```\n:::\n\n\nSampling from clusters:\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(class.seed)\n# sampling the clusters\n(sampled_clusters <- sample(all_clusters, size = m, replace = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2019 2020 2022 2018 2023\n```\n\n\n:::\n\n```{.r .cell-code}\n# new dataframe of just sampled clusters\ncluster.sample <- sampling.frame[sampling.frame$cluster %in% sampled_clusters, c('fixed_id')]\n\n# placeholder for weights\ncluster.sample$cluster_prob <- 1\n```\n:::\n\n\n> Need to add weights manually since the `sampling` package was not used. \n\n\n## Create sampling indicators and write back to Google sheets. \n\nEach method will randomly sample a different group of records, there undoubtedly will be substantial overlap. To keep track of which records were chosen in each design, we create separate variables for each design strategy containing the inclusion probability for that specific design. These variables are then added back to the sampling frame in Google Sheets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample.these <- sampling.frame %>% \n  select(fixed_id) %>% \n  left_join(srs.sample) %>%\n  left_join(strata.major.sample) %>% \n  left_join(strata.year.sample) %>% \n  left_join(cluster.sample) \n\nhead(sample.these)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  fixed_id srs_prob strata_major_prob strata_year_prob cluster_prob\n     <dbl>    <dbl>             <dbl>            <dbl>        <dbl>\n1        1    0.503             0.512            0.517           NA\n2        2    0.503             0.512           NA               NA\n3        3    0.503            NA               NA               NA\n4        4    0.503            NA               NA               NA\n5        5    0.503             0.505            0.517           NA\n6        6    0.503             0.5              0.517           NA\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsheets4::range_write(frame.url, \n                     data = sample.these[-1], \n                     range = \"Q1:T299\", \n                     col_names = TRUE)\n```\n:::\n",
    "supporting": [
      "project_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}