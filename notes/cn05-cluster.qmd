---
title: "Cluster Sampling"
description: "When units are not necessarily nicely defined, even when the population is. "
author: DRAFT
date: 4/01/25
execute: 
  error: true
  warning: false
  message: false
---

```{r}
library(tidyverse);library(knitr)
library(sampling); library(survey)
```

# Introduction

:::{.callout-important}
#### Sampling Units
A **psu** or **psus** (plural) is the shortening of the term, primary sampling unit(s). These are the sampling units in a cluster sample. An alternate term is **cluster**.

A **ssu** or **ssus** (plural) is the shortening of the term, secondary sampling unit(s). These are the observation units observed within our clusters.
:::

### Example of Clustering:

When taking a survey of a community, rather than do an SRS of households, you might break up the community into blocks and take an SRS of blocks and sample all or some of the households that fall within those blocks. The blocks are your psus, and the households are your ssus. This method might be less costly if you were doing an in person survey, but might also be less accurate.

## Why use Cluster Sampling?
Clustering is most common for its application.The purpose of stratifying a sample before was to better your prediction or accuracy when the variance varied quite differently among the population. It is not quite the same for Cluster Sampling, for it actually decreases in precision due to some positive correlation between unmeasurable factors that effect certain specific clusters. 

We use Cluster Sampling when: 
1. It may be unfeasible or expensive to construct a sampling frame of the population, and breaking into groups may make sampling doable.
2. In some populations, it’s less costly to sample in clusters, in terms of travel and time.

![Textbook Figure 5.1. Contrasting stratified sampling with one-stage cluster sampling.](../figs/fig5_1.jpg)


## When clusters are Ignored

When clusters are ignored in the design or analysis phase, the sample can mistakenly be treated as if it were using the simple random sampling design. When they are ignored they can lead to incorrect formulas that have inaccurate conclusions. For example, when we analyze our sample as an SRS the variability can be underestimated on account of the clusters being designed to be more similar and homogeneous compared to an SRS and stratified sample. This will lead to values that are too small and confidence intervals that can be too narrow.


:::{.callout-tip}
#### Example: Studies in education
Many studies in education (either involving teachers, students, other faculty, etc.) use cluster sampling for data collection. Clusters can include entire schools or even just individual classrooms. This is much more cost effective and logistically simpler than taking an SRS of individuals (students, staff, etc.).

One known example [conducted by Basow and Silberg (1987) and Basow and Martin (2012)] examined whether students rated professors differently based on gender (female vs male professors). 

:::

* In this study they took 16 female and 16 male professors and matched them by their subjects, experience, and tenure status. 
* They then sampled each of their classrooms full of students for data collection.
* They, in total, collected 1029 individual student responses but since we are using cluster sampling the sample size will be n = 32 as there are 32 total clusters. The analysis would be wrong if we ignored that it was a cluster sample and treated it as an SRS of size 1029.

This is a great real world example of how cluster sampling can streamline collecting important data while still gaining valuable insight.


# Notation & Formulas

In SRS, each individual element is the sampling unit, and has an equal chance to be sampled.  In stratified sampling, the population is divided into  $H$ known strata, and a sample is taken from each. Our sampling unit in the cluster design is the entire cluster, or primary sampling unit $psus$, and not the individual elements.

In stratified sampling we have our entire population being $N$ total population of each individual element, whereas our entire universe in cluster sampling is the number of clusters, that is $N$ is the number of $psus$.

⚠️ Note notation change!

* $y_{ij}$: measurement for the $j$th element in $i$th psu
* $N$: the number of clusters (psus) in the population
    * $n$: the number of psus from the sample
* $M_{i}$: number of ssus in psu $i$ in the population
    * $m_i$: the number of ssu's in psu $i$ from the sample
* $M_{0}$: total number of ssus in the population  

| Population Quantity | Estimator $(\hat{\theta})$ | Estimated variance of $(\hat{\theta})$ |
|---------------------|----------------------|-----------------------------|
| Total in psu $i$: $t_{i}=\sum_{j} y_{ij}$ | $\hat{t}_{i} = \frac{M_{i}}{m_i}\sum_{j} y_{ij}$ | - |
| Variance of psu totals : $S_t^2 = \frac{1}{N-1} \sum_{i} \left( t_i - \frac{t}{N} \right)^2$ | $s_t^2 = \frac{1}{n-1} \sum_{i} \left( t_i - \frac{\hat{t}}{N} \right)^2$ | _AKA variance between psu_|
| Overall Total: $t = \sum_{i} t_i$ | $\hat{t} = \frac{N}{n}\sum_{i} \hat{t}_i$ | $N^2 \left(1 - \frac{n}{N}\right) \frac{s_t^2}{n}$  |
| mean in psu $i$: $\mu_{i} = \frac{1}{M_i} \sum_{j} y_{ij}$  | $\bar{y}_{i} = \frac{1}{m_i} \sum_{j} y_{ij}$  | $s_{i}^{2} = \frac{1}{m_i-1} \sum_{j} (y_{ij}-\bar{y}_{i})^2$ (_AKA variance within psu_)|
| Overall mean: $\mu = \frac{1}{M_0} \sum_{i} \sum_{j} y_{ij}$  | $\bar{y} = \frac{\hat{t}}{NM}$  | $\left( 1 - \frac{n}{N} \right) \frac{s_t^2}{nM^2}$ |


Overall there are many differences between clustering, stratification, and SRS, that are important to note.




------------------------------------------------------------------------

# One-Stage Clustering Sampling

## Equal size clusters: Estimation

One-stage clustering is the type of clustering you're probably already familiar with - either all (or none) of the observations inside of a cluster (psu) are sampled.

While this is an unrealistic scenario for most statistical work in the social sciences, agricultural or industrial surveys may be able to take advantage of the much simpler process that equal size clustering brings. 

Because the psus are selected through an SRS, we can use the per-cluster estimates as single observations in an SRS. There's no need to consider the individual ssus within each cluster. **Important distinction: we treat this as an SRS of $n$ psus, not an SRS of $nM$ observational units.** 

In this setup, we typically aim to estimate the population total or mean of a variable of interest based on the totals from each sampled cluster.

:::{.callout-tip icon=true}
### Example: Average GPA in a dorm

Perhaps we want to estimate the average GPA in a college dormitory with a one-stage cluster design. The dorm consists of 100 units, each with 4 students. Here's the process: 

1. An SRS is conducted to select 5 clusters.  
2. All 4 students (ssus) per dormitory unit (psus) have their GPAs measured
3. Calculate your estimates based on your *psu* statistics, not your ssu measurements.

_(Slightly modified version of Example 5.2 from Lohr's R Companion to Sampling 3rd ed. Page 57. DOI: 10.1201/9781003228196-5)_

:::

#### Using the `survey` package 

```{r}
gpa <- readr::read_csv(here::here("data", "gpa.csv"))
N <- 100 # total dorm population (this won't be NROW(gpa)!)
n <- 5   # total number of clusters/psus selected
M <- 4   # observational units/ssus selected per psu
```

Create a survey design for one-stage clustering
```{r}
OSC_gpa <- svydesign(id = ~suite,
                     weights = ~wt,#already on the data set
                     fpc = ~rep(100,20),
                     data = gpa)
```

calculate the mean GPA and 95% confidence interval using survey package
```{r}
(mean_gpa <- svymean(~gpa, OSC_gpa))
(mean_gpa_confint <- svymean(~gpa, OSC_gpa) |> confint())
```

The point estimate for GPA is `r round(mean_gpa[1], 2)`, with a 95% confidence interval of `r round(mean_gpa_confint[1, 1], 2)` to `r round(mean_gpa_confint[1, 2], 2)`.

#### 

### Sampling Weights

In one-stage cluster sampling with equal-sized clusters, each cluster is treated as a single observation. The sampling weight for each observation unit $j$ in PSU $i$ is based on the inverse probability of that PSU being selected. This results in a **self-weighting sample**, meaning every sampled element gets the same weight.

$$
w_{ij} = \frac{N}{n}
$$

The total sampling weight across all sampled units equals the total number of units in the population ($NM$). Make sure to always verify that the sum of your weights matches the population size. Population total and mean can also be estimated using these weights by summing the weighted values or averaging them appropriately. 

This weighting approach allows you to use one-stage cluster sampling estimates similarly to how you'd handle stratified or SRS data, despite the cluster structure.

----

## Equal size clusters: Theory

### Comparing a cluster sample with an SRS of the same size



:::{.callout-important}
### ANalysis Of VAriance
Don't recall how ANOVA works to break up the variance into components? See [this great video](https://www.youtube.com/watch?v=W36DMVJ4Ibo&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD) from the Open Intro Statistics author, Mine Cetinkaya-Rundel
:::

:::{.callout-important}
### MSB (Mean Squared Between psus)
text

:::

:::{.callout-important}
### MSW (Mean Squared Within psus)
text

:::

:::{.callout-important}
#### ICC (Intraclass Correlation Coefficient)
text

:::

:::{.callout-important}
#### R Squared
text

:::



:::{.callout-tip}
#### Example 5.3. Consider two artificial populations
text

:::


:::{.callout-tip}
#### Example 5.5. When is a cluster not a cluster? 
text

:::


## Unequal size clusters

> advice: summarize motivating example. Explain unbiasedness and show formulas. 
> Then bullet point rest of section

### Ratio Estimation


### Estimation using weights



:::{.callout-tip icon=false}
### Example. High school Algebra
Consider a population of 187 high school algebra classes in a city. An investigator takes an SRS of classes, and gives each student in the sampled classes a test about function knowledge. The (hypothetical) data are given in the file `algebra.csv`. 

a. Load in the data and look at the first few rows. Explain what the values in each column mean.
b. Plot the distribution of test score by class. Interpret your graph by comparing the medians, ranges, and variances across classes. What do you notice?
c. How many _psus_ are there? What is the _psu_ with the highest number of _ssus_? Which one has the least? You must answer this question using R functions such as`unique` or `table`. Don't count this by hand (practice for when you have a billion rows)
d. Add variables containing the weights and the `fpc` to this data set. 
e. Using the proper functions from the `survey` package, estimate the population average algebra score, with a 95% interval and interpret your interval. Be sure to NOT assume a Z-distribution for this confidence interval but use the `degf` function to get the proper degrees of freedom out of the survey design object and pass it to the `confint` function. 
:::

------------------------------------------------------------------------

# Two-Stage Clustering Sampling

![Textbook Figure 5.2. Differences between one-stage and two-stage cluster sampling.](../figs/fig5_2.jpg)

## Unbiased estimator of population total.

## Survey weights

## Variance estimation for two-stage cluster samples.

### Simplified version



:::{.callout-tip icon=true}
### Example 5.7: More estimation of math scores. 

The file `schools.csv` contains data from a two-stage sample of students from hypothetical classes. The final weights are provided in the variable `finalwt`. 

a) Create side by side boxplots for the math score for sampled schools. Which do you think is larger, the within or between cluster variance? 
b) Create an ANOVA table for this example. Is your interpretation from the graph upheld by this analysis? 
c) Estimate with proper 95% CI the average math score for the population of students under consideration. _Do not include a value for the `fpc` in this example_. 
:::

:::{.callout-warning icon=false}
### You Try It: The case of the six-legged puppy.


:::

# Chapter Summary




